{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "pP6wy5xkLxUs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/falon-go-weeee/SD-fast-all-models/blob/main/InvokeAi_webui_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y9EBc437WDOs"
      },
      "outputs": [],
      "source": [
        "#@markdown # Connect Google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install Requirements\n",
        "#The code below installs 3.10 (assuming you now have 3.8) and restarts environment, so you can run your cells.\n",
        "\n",
        "import sys #for version checker\n",
        "import os #for restart routine\n",
        "\n",
        "if '3.10' in sys.version:\n",
        "  print('You already have 3.10, nothing to install')\n",
        "else:\n",
        "  #install python 3.10 and dev utils\n",
        "  #you may not need all the dev libraries, but I haven't tested which aren't necessary.\n",
        "  !sudo apt-get update -y\n",
        "  !sudo apt-get install python3.10 python3.10-dev python3.10-distutils libpython3.10-dev \n",
        "  !sudo apt-get install python3.10-venv binfmt-support #recommended in install logs of the command above\n",
        "\n",
        "  #change alternatives\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.8 1\n",
        "  !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2\n",
        "\n",
        "  # install pip\n",
        "  !curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
        "  !python3 get-pip.py --force-reinstall\n",
        "\n",
        "  #install colab's dependencies\n",
        "  !python3 -m pip install setuptools ipython ipython_genutils ipykernel jupyter_console prompt_toolkit httplib2 astor\n",
        "\n",
        "  #minor cleanup\n",
        "  !sudo apt autoremove\n",
        "\n",
        "  #link to the old google package\n",
        "  !ln -s /usr/local/lib/python3.8/dist-packages/google /usr/local/lib/python3.10/dist-packages/google\n",
        "  #this is just to verify if 3.10 folder was indeed created\n",
        "  !ls /usr/local/lib/python3.10/\n",
        "\n",
        "  #restart environment so you don't have to do it manually\n",
        "  #os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "8PN7MajE_ri7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Install InvokeAi\n",
        "from IPython.display import clear_output\n",
        "import sys\n",
        "import os\n",
        "print(\"version:\", sys.version)\n",
        "\n",
        "!pip install virtualenv\n",
        "!sudo apt update && sudo apt install -y libglib2.0-0 libgl1-mesa-glx\n",
        "clear_output()\n",
        "\n",
        "!wget -c https://github.com/invoke-ai/InvokeAI/files/10254727/InvokeAI-installer-2.2.4-p5-linux.zip -O /content/InvokeAI.zip\n",
        "!unzip InvokeAI.zip\n",
        "clear_output()\n",
        "\n",
        "!rm -rf /content/InvokeAI-Installer/install.sh\n",
        "!wget -c https://raw.githubusercontent.com/falon-go-weeee/SD-fast-all-models/main/invokeai/install.sh -P /content/InvokeAI-Installer/\n",
        "!wget -c https://raw.githubusercontent.com/falon-go-weeee/SD-fast-all-models/main/invokeai/configure_invokeai.py -P /content/\n",
        "clear_output()\n",
        "\n",
        "Huggingface_token = \"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\" #@param {type:\"string\"}\n",
        "!chmod +x /content/InvokeAI-Installer/install.sh\n",
        "!/content/InvokeAI-Installer/install.sh $Huggingface_token\n",
        "clear_output()\n",
        "\n",
        "def install_bore():\n",
        "  if not os.path.exists('/usr/bin/bore'):\n",
        "    !wget https://github.com/ekzhang/bore/releases/download/v0.4.0/bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz\n",
        "    !tar -xf bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz\n",
        "    !rm -f bore-v0.4.0-x86_64-unknown-linux-musl.tar.gz\n",
        "    !cp bore /usr/bin/bore\n",
        "    !rm -rf bore\n",
        "install_bore()\n",
        "if not os.path.exists('/tools/node/bin/lt'):\n",
        "  !npm install -g localtunnel\n",
        "clear_output()\n",
        "\n",
        "!rm -rf /invokeai/invoke.sh\n",
        "!wget -c https://raw.githubusercontent.com/falon-go-weeee/SD-fast-all-models/main/invokeai/invoke.sh -P /invokeai/\n",
        "!chmod +x /invokeai/invoke.sh\n",
        "clear_output()\n",
        "\n",
        "print('\u001b[1;32m InvokeAI Installation Download Complete')"
      ],
      "metadata": {
        "id": "M4f3f8_PH-LX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP6wy5xkLxUs"
      },
      "source": [
        "####**Stable Diffusion Models Database Downloads**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eNXFwJpfEBo5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import re\n",
        "import requests\n",
        "\n",
        "#@markdown #Stable Diffusion Models Database Downloads\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def install_mega():\n",
        "  HOME = os.path.expanduser(\"~\")\n",
        "  if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "      hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                  \"OneClickRun/master/res/ocr.py\"\n",
        "      urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "  from ocr import (\n",
        "      runSh,\n",
        "      loadingAn,\n",
        "  )\n",
        "\n",
        "  # MEGAcmd installing\n",
        "  if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "      loadingAn()\n",
        "      print(\"Installing MEGA ...\")\n",
        "      runSh('sudo apt-get -y update')\n",
        "      runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "      runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "      runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "      print(\"MEGA is installed.\")\n",
        "  clear_output()\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "\n",
        "def transfare(URL, OUTPUT_PATH):\n",
        "    import codecs\n",
        "    decoder = codecs.getincrementaldecoder(\"UTF-8\")()\n",
        "    cmd = [\"mega-get\", URL, OUTPUT_PATH]\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        print(line)\n",
        "\n",
        "#@markdown - (torrent) (direct) (generate) (mega) (gdrive) (huggingface) -- working links\n",
        "#@markdown\n",
        "#@markdown - use generate for CIVITAi models.\n",
        "#@markdown\n",
        "#@markdown - Download resume not working for (generate) links, downloads will restart.\n",
        "\n",
        "!wget -c https://raw.githubusercontent.com/falon-go-weeee/SD-fast-all-models/main/Stable%20Diffusion%20Models%20Database%20Entry.csv -P /content/\n",
        "clear_output()\n",
        "\n",
        "Model = \"none\" #@param [\"none\", \"Anything-V3.0 fp16 (huggingface)\",\"Anything-V3.0 fp32 (huggingface)\", \"Anything-V3.0 fp16 [38c1ebe3] (torrent)\", \"Anything-V3.0 fp32 [1a7df6b8] (torrent)\", \"Anything-V3.0 Full EMA [6569e224] (torrent)\", \"Cafe Unofficial Instagram TEST Model [50b987ae] (torrent)\", \"SmirkingFace SF_EB_1.0_ema_vae.ckpt [7f115f17] (generate)\", \"SmirkingFace SF_EB_1.0_ema_vae.ckpt [7f115f17] (torrent)\", \"SmirkingFace SF_EB_1.0_noema_vae.ckpt [7010a578] (generate)\", \"SmirkingFace SF_EB_1.0_noema_vae.ckpt [7010a578] (torrent)\", \"SXD-v0.8 (generate)\", \"gg1342_testrun1_pruned.ckpt [43076286] [2ccc3e58] (torrent)\", \"Pyro's Blowjob Model v1.0 [9b5251e8] (generate)\", \"Pyro's Blowjob Model v1.0 [9b5251e8] (mega)\", \"Pyro's POV Cowgirl Model Model A (mega)\", \"Pyro's POV Cowgirl Model Model B (mega)\", \"Easter easter_e5 [da453598] (mega)\", \"Easter easter_e5 [da453598] (torrent)\", \"Easter easter_e4 [3997b596] (mega)\", \"Easter easter_e3 [9c5ade34] (mega)\", \"Easter easter_e3 [9c5ade34] (torrent)\", \"Hentai Diffusion HD-16.ckpt [e2ec4647] (huggingface)\", \"Hentai Diffusion RD1412.ckpt [2140af02] [5b87f0e6] [4fdde306] (huggingface)\", \"Hentai Diffusion RD1212.ckpt [a1f5a67e] [37b5398c] [3b3459c8] (huggingface)\", \"Bare Feet / Full Body b4_t16_noadd [03e33bb4] [2bd8166c] [9012c514] (torrent)\", \"Bare Feet / Full Body b4_t16_noadd [03e33bb4] [2bd8166c] [9012c514] (torrent)\", \"Lewd Diffusion 70k 2e [f4030c43] (torrent)\", \"Lewd Diffusion 70k 1e [950d323b] (torrent)\", \"Lewd Diffusion v0 [07734b46] (torrent)\", \"Yiffy yiffy-e18.ckpt [50ad914b] (direct)\", \"Yiffy yiffy-e18.ckpt [50ad914b] (torrent)\", \"Yiffy yiffy-e15.ckpt [4bb305c0] (direct)\", \"Yiffy yiffy-e15.ckpt [4bb305c0] (generate)\", \"Yiffy yiffy-e15.ckpt [4bb305c0] (direct)\", \"Yiffy yiffy-e15.ckpt [4bb305c0] (torrent)\", \"Yiffy yiffy-e13.ckpt [778b38ae] (direct)\", \"Yiffy yiffy-e13.ckpt [778b38ae] (torrent)\", \"SnackBar-General-V1-E11 [16d5a5c7] (generate)\", \"SnackBar-General-V1-E11 [16d5a5c7] (torrent)\", \"Furry Furry_epoch4.ckpt [323f8dd8] (torrent)\", \"Furry Furry_epoch4.ckpt [323f8dd8] (generate)\", \"Furry Furry_epoch4.ckpt [323f8dd8] (direct)\", \"Furry Furry_epoch1.ckpt [0c891127] (torrent)\", \"Furry Furry_epoch1.ckpt [0c891127] (direct)\", \"Furry Furry_epoch0.ckpt [8c19ee5a] (direct)\", \"Zack3D_Kinky-v1.ckpt [1a75d5c6] (generate)\", \"Zack3D_Kinky-v1.ckpt [1a75d5c6] (torrent)\", \"Anal Vore AVHumanFurryPony7.ckpt [68e2e32d] (mega)\", \"R34 r34_e4.ckpt [6e45cf2c] (torrent)\", \"R34 r34_e4.ckpt [6e45cf2c] (mega)\", \"R34 r34_e3.ckpt [57ea6f43] (mega)\", \"R34 r34_e2.ckpt [778b68b1] (torrent)\", \"R34 r34_e2.ckpt [778b68b1] (mega)\", \"R34 r34_e1.ckpt [f9000e4e] (torrent)\", \"R34 r34_e1.ckpt [f9000e4e] (mega)\", \"R34 r34_150k_epoch0-pruned-fp16.ckpt [7dc34283] (torrent)\", \"R34 r34_150k_epoch0.ckpt [7c3721c3] (torrent)\", \"R34 r34_150k_epoch0.ckpt [7c3721c3] (mega)\", \"Gape gape60 [25396b85] (torrent)\", \"Gape gape60 [25396b85] (mega)\", \"Gape gape22 [d69e1a23] (torrent)\", \"Gape gape22 [d69e1a23] (mega)\", \"Gape gape18 (torrent)\", \"sd-wikiart-v2.ckpt. [8f32b8df] (torrent)\", \"Pachu-Diffusion [54d5d199] (huggingface)\", \"TestFurry_5.ckpt [b1f1855e] (torrent)\", \"cookie_sd_pony_run_a12 float16 [2ce7dcf5] [67ff5385] (direct)\", \"cookie_sd_pony_run_a12 float16 [2ce7dcf5] [67ff5385] (torrent)\", \"cookie_sd_pony_run_a12 float32 [2ce7dcf5] [67ff5385] (direct)\", \"cookie_sd_pony_run_a12 float32 [2ce7dcf5] [67ff5385] (mega)\", \"pony-diffusion pony-diffusion-v2 [5bdc40aa] (mega)\", \"pony-diffusion pony-diffusion-v1 [9070b574] (mega)\", \"mio-wd-v1.2-e24-ex-ad [125f9ece] (torrent)\", \"mio-wd-v1.2-e24-ex-ad [125f9ece] (huggingface)\", \"fubuki-ld-v1-e13-ex-ad [2af6d20f] (torrent)\", \"asuka-ld-v1-e4-ex-ad [87074080] (torrent)\", \"tomoko-kuroki-ld-v1-e20-ex-ad [6095e7ab] (torrent)\"]\n",
        "merged_model = \"none\" #@param [\"none\", \"BerryMix [19810fe6] (torrent)\", \"FreckleGuy's mix (torrent)\", \"HassansBlend (torrent)\", \"HassansBlend (gdrive)\", \"HassansBlend (mega)\", \"MMDv1-18 (huggingface)\", \"MMDv1-18 (huggingface)\", \"samdoartsultmerge.ckpt [8687d7a5] (torrent)\", \"samdoartsultmerge.ckpt [8687d7a5] (huggingface)\", \"70gg30LD70k.ckpt [402dc090] (torrent)\", \"wd1-2_sd1-4_merged.ckpt [2037c511] (torrent)\"]\n",
        "dreambooth_model = \"none\" #@param [\"none\", \"Hiten girl_anime_8k_wallpaper_4k.ckpt [7831dea3] (huggingface)\", \"nanachiDB-42imgs-5000steps.ckpt (mega)\", \"rizaDB-54imgs-4500steps.ckpt (mega)\", \"bea-14000-pruned-fp16.ckpt [802a681b] (torrent)\", \"bea-14000-pruned-fp16.ckpt [802a681b] (torrent)\", \"2b-10000-pruned-fp16.ckpt [8cf4478f] (torrent)\", \"misato-10000-pruned-fp16.ckpt [c51e4c77] (torrent)\", \"hilda-v2-8000-pruned-fp16.ckpt [d2c8eef1] (torrent)\", \"nagatoro-4000-pruned-fp16.ckpt [8c5ff341] (torrent)\", \"gawr_gura-4000-pruned-fp16.ckpt [cbd4da60] (torrent)\", \"mori_calliope-4000-pruned-fp16.ckpt [6cb50083] (torrent)\", \"towa-4000-pruned-fp16.ckpt [d578d3c1] (torrent)\", \"Gawr_Gura_450img.ckpt [e7883abf] (huggingface)\", \"Emilia_CustReg_3k.ckpt [2660cf9a] (huggingface)\", \"Star Fox Krystal (mega)\", \"Star Fox Krystal (generate)\", \"StudioGhibli [10c6aa67] (huggingface)\", \"Arcane Vi vimod.ckpt [e02601f3] (huggingface)\", \"irlhyperbreasts_9k.ckpt [5ce8b6ec] (torrent)\", \"irlhyperbreasts_9k.ckpt [5ce8b6ec] (gdrive)\", \"hyperass v1 (torrent)\", \"hyperbreasts: v3 (torrent)\", \"hyperpreg: v2 (realism and anime) (torrent)\", \"hyperpreg: v1.1 (realism) (torrent)\", \"hyperpreg: v1 (realism) (torrent)\", \"Kurisu (torrent)\", \"Kurisu Visual Novel Official artist (Huke) [eda12c8e] (torrent)\", \"dreambooth_lain_girl.ckpt [e7629bf8] (torrent)\", \"dreambooth_lain_girl.ckpt [e7629bf8] (mega)\", \"Gyokai/onono imoko (mega)\", \"futacum_r34.ckpt (gdrive)\", \"futanari_v2_e3_s10000.ckpt (gdrive)\", \"Futa_step_3200_10_27.ckpt (gdrive)\", \"Wayne Barlowe [e0c27550] (torrent)\", \"Wayne Barlowe [e0c27550] (generate)\", \"Wayne Barlowe [e0c27550] (generate)\", \"Blacked POV blowjob [8467f44f] (torrent)\", \"Blacked POV blowjob [8467f44f] (generate)\", \"Zeipher F222 Female Nude (better anatomy) (torrent)\", \"Zeipher F222 Female Nude (better anatomy) (generate)\", \"LOKEAN_PUPPYSTYLE_POV.ckpt [e02601f3] (direct)\", \"LOKEAN_MISSIONARY_POV.ckpt [e02601f3] (direct)\", \"Reverse cowgirl s4629674.ckpt [e285da0d] (torrent)\", \"Reverse cowgirl s4629674.ckpt [e285da0d] (mega)\", \"elden-ring-diffusion [16d77205] (huggingface)\", \"modern-disney-diffusion [ccf3615f] (huggingface)\", \"Arcane-Diffusion [318a302e] (huggingface)\", \"classic-anim-diffusion [be7ddafc] (huggingface)\", \"bukkake [b4a14787] (torrent)\", \"bukkake [b4a14787] (mega)\", \"DCAU [2fd6057b] (huggingface)\", \"Raven anime.ckpt (mega)\", \"Raven Western.ckpt (mega)\", \"oshinobu-pruned.ckpt (torrent)\", \"henreader_final_pruned.ckpt [e5803978] (torrent)\", \"oshino_shinobu_final_pruned.ckpt (torrent)\", \"Latex's Abandoned Style (torrent)\", \"Latex's Abandoned Style (generate)\", \"Belle Dephine [32cbf6c8] (torrent)\", \"Belle Dephine [32cbf6c8] (gdrive)\", \"Cal Arts Style (huggingface)\", \"Pixel Landscapes V1 (huggingface)\", \"Pixel Landscapes V1 (gdrive)\", \"MicroWorlds (mega)\", \"MicroWorlds (gdrive)\", \"App Icons Generator V1 (gdrive)\", \"Pixel Art V1 (gdrive)\", \"VTT RPG (generate)\", \"Comic Diffusion (huggingface)\", \"SD_PixelArt_SpriteSheet_Generator (huggingface)\", \"midjourney-v4-diffusion (huggingface)\", \"BloodborneDiffusion (huggingface)\", \"samdoesarts_style [85b77ff9] (torrent)\", \"samdoesarts_style [85b77ff9] (generate)\", \"samdoesarts_style [85b77ff9] (generate)\", \"JWST Deep Space Diffusion (huggingface)\", \"copeseethemaldchinai_10000.ckpt (samdoesart) [32186669] (torrent)\", \"copeseethemaldchinai_10000.ckpt (samdoesart) [32186669] (mega)\", \"CopeSeetheMald-berry200_20400.ckpt (samdoesart) [fa49a214] (torrent)\", \"CopeSeetheMald-berry200_20400.ckpt (samdoesart) [fa49a214] (mega)\", \"CopeSeetheMald-200_20400.ckpt (samdoesart) [95f071f9] (torrent)\", \"CopeSeetheMald-200_20400.ckpt (samdoesart) [95f071f9] (mega)\", \"Black Souls bs_1500.ckpt [37ec0dc9] (torrent)\", \"Black Souls bs_1500.ckpt [37ec0dc9] (mega)\", \"jaggy92500.ckpt [93423a00] (torrent)\", \"jaggy92500.ckpt [93423a00] (mega)\", \"ykgl.ckpt (y2k cgi girls) (mega)\", \"CSRmodel (cutesexyrobutts) [b77538cc] (torrent)\", \"CSRmodel (cutesexyrobutts) [b77538cc] (generate)\", \"Pepestyle (huggingface)\", \"dbmai [e02601f3] (torrent)\", \"dbmai [e02601f3] (gdrive)\", \"gigachad-diffusion (huggingface)\", \"Complex-Lineart (huggingface)\"]\n",
        "\n",
        "#@markdown huggingface token\n",
        "token = \"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\" #@param {type:\"string\"}\n",
        "\n",
        "data= pd.read_csv('/content/Stable Diffusion Models Database Entry.csv')\n",
        "\n",
        "#model_url = 'https://drive.google.com/file/d/1704mmNPEzSbHEBKNmfQ4RnhnBUUx646k'\n",
        "#model_download_link_type = 'gdrive'\n",
        "\n",
        "def Download_model(Model, model_url, model_download_link_type, token, isVAE=False, istexinv=False):  \n",
        "  print(model_url)\n",
        "\n",
        "  OUTPUT_PATH = '/content/gdrive/MyDrive/invokeai/models/ldm/stable-diffusion-v1/'\n",
        "  if isVAE:\n",
        "    OUTPUT_PATH = '/content/gdrive/MyDrive/invokeai/models/ldm/stable-diffusion-v1'\n",
        "  if istexinv:\n",
        "    OUTPUT_PATH = '/content/gdrive/MyDrive/invokeai/embeddings'\n",
        "\n",
        "  !mkdir $OUTPUT_PATH\n",
        "  \n",
        "  print(OUTPUT_PATH)\n",
        "\n",
        "  if model_download_link_type == 'torrent':\n",
        "    install_aria()\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o {OUTPUT_PATH}/{Model}.ckpt '{model_url}'\n",
        "  \n",
        "  if model_download_link_type == 'direct':\n",
        "    if istexinv:\n",
        "      !wget -c '{model_url}' -O '{OUTPUT_PATH}{Model}.pt'\n",
        "    else:\n",
        "      !wget -c '{model_url}' -P $OUTPUT_PATH\n",
        "\n",
        "  if model_download_link_type == 'generate':\n",
        "    r = requests.get(model_url, stream = True) \n",
        "    if isVAE: \n",
        "      with open(f'{OUTPUT_PATH}{Model}.vae.pt', \"wb\") as file: \n",
        "          for block in r.iter_content(chunk_size = 1024):\n",
        "              if block: \n",
        "                  file.write(block)\n",
        "    if istexinv:\n",
        "      with open(f'{OUTPUT_PATH}{Model}.pt', \"wb\") as file: \n",
        "          for block in r.iter_content(chunk_size = 1024):\n",
        "              if block: \n",
        "                  file.write(block)\n",
        "    else:\n",
        "      with open(f'{OUTPUT_PATH}{Model}.ckpt', \"wb\") as file: \n",
        "          for block in r.iter_content(chunk_size = 1024):\n",
        "              if block: \n",
        "                  file.write(block)\n",
        "\n",
        "  if model_download_link_type == 'mega':\n",
        "    if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "      install_mega()\n",
        "    transfare(model_url, OUTPUT_PATH)\n",
        "\n",
        "  if model_download_link_type == 'gdrive':\n",
        "    if isVAE:\n",
        "      !gdown -c --fuzzy '{model_url}' -O $OUTPUT_PATH$Model'.vae.pt'\n",
        "    if istexinv:\n",
        "      !gdown -c --fuzzy '{model_url}' -O $OUTPUT_PATH$Model'.pt'\n",
        "    else:\n",
        "      !gdown -c --fuzzy '{model_url}' -O $OUTPUT_PATH$Model'.ckpt'\n",
        "\n",
        "  if model_download_link_type == 'huggingface':\n",
        "    if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "    user_header = f\"\\\"Authorization: Bearer {token}\\\"\"\n",
        "    if istexinv:\n",
        "      !wget -c --header={user_header} '{model_url}' -O '{OUTPUT_PATH}{Model}.pt'\n",
        "    else:\n",
        "      !wget -c --header={user_header} '{model_url}' -P $OUTPUT_PATH  \n",
        "  #clear_output()\n",
        "\n",
        "if not Model == \"none\":\n",
        "  model_url = data.loc[data['Model_Name'] == Model].Model_Download_link.values.astype(str)\n",
        "  model_download_link_type = data.loc[data['Model_Name'] == Model].Model_Download_link_Type.values.astype(str)\n",
        "  model_url = np.array2string(model_url)[2:-2]\n",
        "  Download_model(Model, model_url, model_download_link_type, token, isVAE=False)\n",
        "  \n",
        "  vae_url = data.loc[data['Model_Name'] == Model].VAE_Download_link.values.astype(str)\n",
        "  vae_download_link_type = data.loc[data['Model_Name'] == Model].VAE_Download_link_Type.values.astype(str)\n",
        "  vae_url = np.array2string(vae_url)[2:-2]\n",
        "  if not vae_url==\"\":\n",
        "    Download_model(Model, vae_url, vae_download_link_type, token, isVAE=True)\n",
        "\n",
        "if not merged_model == \"none\":\n",
        "  Model = merged_model\n",
        "  model_url = data.loc[data['Model_Name'] == Model].Model_Download_link.values.astype(str)\n",
        "  model_download_link_type = data.loc[data['Model_Name'] == Model].Model_Download_link_Type.values.astype(str)\n",
        "  model_url = np.array2string(model_url)[2:-2]\n",
        "  Download_model(Model, model_url, model_download_link_type, token, isVAE=False)\n",
        "\n",
        "  vae_url = data.loc[data['Model_Name'] == Model].VAE_Download_link.values.astype(str)\n",
        "  vae_download_link_type = data.loc[data['Model_Name'] == Model].VAE_Download_link_Type.values.astype(str)\n",
        "  vae_url = np.array2string(vae_url)[2:-2]\n",
        "  if not vae_url==\"\":\n",
        "    Download_model(Model, vae_url, vae_download_link_type, token, isVAE=True)\n",
        "\n",
        "if not dreambooth_model == \"none\":\n",
        "  Model = dreambooth_model\n",
        "  model_url = data.loc[data['Model_Name'] == Model].Model_Download_link.values.astype(str)\n",
        "  model_download_link_type = data.loc[data['Model_Name'] == Model].Model_Download_link_Type.values.astype(str)\n",
        "  model_url = np.array2string(model_url)[2:-2]\n",
        "  Download_model(Model, model_url, model_download_link_type, token, isVAE=False)\n",
        "\n",
        "  vae_url = data.loc[data['Model_Name'] == Model].VAE_Download_link.values.astype(str)\n",
        "  vae_download_link_type = data.loc[data['Model_Name'] == Model].VAE_Download_link_Type.values.astype(str)\n",
        "  vae_url = np.array2string(vae_url)[2:-2]\n",
        "  if not vae_url==\"\":\n",
        "    Download_model(Model, vae_url, vae_download_link_type, token, isVAE=True)\n",
        "  \n",
        "#@markdown Custom Model\n",
        "download_custom_model = True #@param {type:\"boolean\"}\n",
        "custom_model_name = \"Sangonomiya_Kokomi\" #@param {type:\"string\"}\n",
        "if download_custom_model:\n",
        "  if custom_model_name == \"\":\n",
        "    custom_model_name = input(\"input custom model name : \")\n",
        "  Model = custom_model_name\n",
        "  model_url = \"https://huggingface.co/Falon/sangonomiya-kokomi/resolve/main/Sangonomiya_Kokomi.ckpt\" #@param {type:\"string\"}\n",
        "  model_download_link_type = \"huggingface\" #@param [\"torrent\", \"mega\", \"direct\", \"gdrive\", \"huggingface\", \"generate\"]\n",
        "  if not model_url==\"\":\n",
        "    Download_model(Model, model_url, model_download_link_type, token, isVAE=False, istexinv=False)\n",
        "    model_weights_loc = '/content/gdrive/MyDrive/invokeai/models/ldm/stable-diffusion-v1/'+Model+'.ckpt'\n",
        "\n",
        "  model_vae_loc = ''\n",
        "  vae_url = \"\" #@param {type:\"string\"}\n",
        "  vae_download_link_type = \"huggingface\" #@param [\"torrent\", \"mega\", \"direct\", \"gdrive\", \"huggingface\", \"generate\"]\n",
        "  if not vae_url==\"\":\n",
        "    Download_model(Model, vae_url, vae_download_link_type, token, isVAE=True, istexinv=False)\n",
        "    model_vae_loc = '/content/gdrive/MyDrive/invokeai/models/ldm/stable-diffusion-v1/'+Model+'.vae.pt'\n",
        "\n",
        "if not os.path.exists('/content/gdrive/MyDrive/invokeai/configs/models.yaml'):\n",
        "  !cp /content/gdrive/MyDrive/invokeai/configs/INITIAL_MODELS.yaml /content/gdrive/MyDrive/invokeai/configs/models.yaml\n",
        "with open('/content/gdrive/MyDrive/invokeai/configs/models.yaml', 'r') as file:\n",
        "  model_yaml = yaml.safe_load(file)\n",
        "model_config = {Model : {'config' : 'configs/stable-diffusion/v1-inference.yaml',\n",
        "                               'default' : True,\n",
        "                               'description' : 'custom model',\n",
        "                               'height' : '512',\n",
        "                               'vae' : model_vae_loc,\n",
        "                               'weights' : model_weights_loc,\n",
        "                               'width' : '512'\n",
        "                              }}\n",
        "model_yaml.update(model_config)\n",
        "with open('/content/gdrive/MyDrive/invokeai/configs/models.yaml', 'w') as file:\n",
        "    yaml.dump(model_config, file)\n",
        "print('\u001b[1;32m'+ Model + ' Download Complete')\n",
        "\n",
        "embedding_name = \"\" #@param {type:\"string\"}\n",
        "if not embedding_name == \"\":    \n",
        "  Model = embedding_name\n",
        "  embedding_url = \"\" #@param {type:\"string\"}\n",
        "  embedding_download_link_type = \"huggingface\" #@param [\"torrent\", \"mega\", \"direct\", \"gdrive\", \"huggingface\", \"generate\"]\n",
        "  if not embedding_url==\"\":\n",
        "    Download_model(Model, embedding_url, embedding_download_link_type, token, isVAE=False, istexinv=True)\n",
        "    print('\u001b[1;32m'+ Model + ' Download Complete')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Start InvokeAi Webui**"
      ],
      "metadata": {
        "id": "CGlOXnrpVTa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Start InvokeAI Webui\n",
        "from IPython.core.interactiveshell import getoutput\n",
        "import time\n",
        "\n",
        "Tunnel = \"bore\" #@param [\"localtunnel\", \"bore\"]\n",
        "if Tunnel == \"localtunnel\":\n",
        "  !nohup lt --port 9090 > srv.txt 2>&1 &\n",
        "  time.sleep(2)\n",
        "  !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(2)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "  print(srv)\n",
        "\n",
        "elif Tunnel == \"bore\":\n",
        "  !nohup bore local 9090 --to bore.pub > srv.txt 2>&1 &\n",
        "  time.sleep(3)\n",
        "  !grep -o 'bore.pub:[^ ]*' /content/srv.txt >srvr.txt\n",
        "  time.sleep(3)\n",
        "  srv= getoutput('cat /content/srvr.txt')\n",
        "  print('http://'+srv)\n",
        "\n",
        "!rm /content/srv.txt\n",
        "!rm /content/srvr.txt\n",
        "\n",
        "!/invokeai/invoke.sh\n",
        "#!/content/gdrive/MyDrive/invokeai/invoke.sh"
      ],
      "metadata": {
        "id": "n4lZFC7PMyJR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}